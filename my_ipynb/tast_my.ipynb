{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cf4dc5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_solution的onset事件数量: 3416\n",
      "train_solution的wakeup事件数量: 3416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:00<00:00, 191.01it/s]\n"
     ]
    }
   ],
   "source": [
    "#提取数据\n",
    "import numpy as np  # 用于数学计算和数组操作\n",
    "import pandas as pd  # 用于数据处理和分析\n",
    "import matplotlib.pyplot as plt  # 用于数据可视化\n",
    "import polars as pl  # 高性能数据处理库，类似于pandas\n",
    "import datetime  # 用于处理日期和时间\n",
    "from tqdm import tqdm  # 用于显示进度条\n",
    "import plotly.express as px  # 用于交互式数据可视化\n",
    "from plotly.subplots import make_subplots  # 用于创建子图\n",
    "import plotly.graph_objects as go  # 用于创建更复杂的图表\n",
    "from sklearn.model_selection import train_test_split  # 用于划分训练集和测试集\n",
    "import sys\n",
    "sys.path.append('/home/zhuangzhuohan/sleep_data')\n",
    "from my_py.my_funs import make_train_dataset_new,load_and_preprocess_data_new,create_features_new,apply_features,analyze_validation_data,analyze_val_data_stats,create_features_float,load_and_preprocess_data_float\n",
    "tolerances = {\n",
    "    'onset': [12, 36, 60, 90, 120, 150, 180, 240, 300, 360],  # 睡眠开始事件的时间容忍度（分钟）\n",
    "    'wakeup': [12, 36, 60, 90, 120, 150, 180, 240, 300, 360]  # 睡眠结束事件的时间容忍度（分钟）\n",
    "}\n",
    "# 1. 加载和预处理数据\n",
    "train_series, train_events, test_series ,series_ids = load_and_preprocess_data_float()\n",
    "# 2. 创建特征\n",
    "features, feature_cols, id_cols = create_features_float()\n",
    "# 3. 应用特征到训练数据\n",
    "train_series = apply_features(train_series, features, id_cols, feature_cols)\n",
    "test_series = apply_features(test_series, features, id_cols, feature_cols)\n",
    "# 2. 定义列名映射（用于评分函数）\n",
    "column_names = {\n",
    "    'series_id_column_name': 'series_id',\n",
    "    'time_column_name': 'step',\n",
    "    'event_column_name': 'event',\n",
    "    'score_column_name': 'score',\n",
    "}\n",
    "# 3. 划分训练集和验证集（70%训练，30%验证）\n",
    "train_ratio = 0.7\n",
    "random_seed = 42\n",
    "train_ids, val_ids = train_test_split(series_ids, train_size=train_ratio, random_state=random_seed)\n",
    "# 4. 收集训练数据\n",
    "train_data = train_series.filter(pl.col('series_id').is_in(train_ids)).collect()\n",
    "# 转换为pandas DataFrame后使用切片方法\n",
    "step_time = 12  # 每1分钟取一个数据点\n",
    "train_data = train_data.to_pandas().iloc[::(step_time)]  # 每step_time分钟取一个数据点\n",
    "train_data = pl.from_pandas(train_data)  # 转回polars DataFrame\n",
    "# 创建训练事件数据（只包含训练集的事件）\n",
    "train_solution_series_id = train_events.filter(pl.col('series_id').is_in(train_ids))\n",
    "train_solution = train_events.filter(pl.col('series_id').is_in(train_ids)).select(['series_id', 'event', 'step']).to_pandas()\n",
    "# 统计真实的onset和wakeup事件数量\n",
    "train_solution_onset_count = len(train_solution[train_solution['event'] == 'onset'])\n",
    "train_solution_wakeup_count = len(train_solution[train_solution['event'] == 'wakeup'])\n",
    "print(f\"train_solution的onset事件数量: {train_solution_onset_count}\")\n",
    "print(f\"train_solution的wakeup事件数量: {train_solution_wakeup_count}\")\n",
    "# 创建训练数据集\n",
    "X_train, y_train = make_train_dataset_new(train_data, train_solution_series_id, feature_cols, id_cols)\n",
    "# 5. 创建验证数据\n",
    "val_data = train_series.filter(pl.col('series_id').is_in(val_ids)).collect()\n",
    "# 6. 创建验证标签（用于评估模型性能）\n",
    "val_solution = train_events.filter(pl.col('series_id').is_in(val_ids)).select(['series_id', 'event', 'step']).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "725b65d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "特征重要性占比:\n",
      "anglez_1v_1m_mean         | 重要性: 0.127885 | 占比: 12.79%\n",
      "enmo_1v_30m_mean          | 重要性: 0.126713 | 占比: 12.67%\n",
      "enmo_1v_15m_mean          | 重要性: 0.124399 | 占比: 12.44%\n",
      "enmo_1v_60m_mean          | 重要性: 0.065882 | 占比: 6.59%\n",
      "enmo_1v_10m_mean          | 重要性: 0.060973 | 占比: 6.10%\n",
      "anglez_1v_1m_max          | 重要性: 0.059063 | 占比: 5.91%\n",
      "enmo_1v_1m_mean           | 重要性: 0.058010 | 占比: 5.80%\n",
      "anglez_1v_240m_max        | 重要性: 0.046219 | 占比: 4.62%\n",
      "anglez_1v_240m_std        | 重要性: 0.033767 | 占比: 3.38%\n",
      "hour                      | 重要性: 0.028366 | 占比: 2.84%\n",
      "enmo_1v_120m_mean         | 重要性: 0.027719 | 占比: 2.77%\n",
      "anglez_1v_60m_max         | 重要性: 0.020520 | 占比: 2.05%\n",
      "anglez_1v_120m_max        | 重要性: 0.019398 | 占比: 1.94%\n",
      "anglez_1v_60m_mean        | 重要性: 0.017985 | 占比: 1.80%\n",
      "anglez_1v_120m_mean       | 重要性: 0.017026 | 占比: 1.70%\n",
      "enmo_1v_240m_max          | 重要性: 0.016742 | 占比: 1.67%\n",
      "anglez_1m_std             | 重要性: 0.015070 | 占比: 1.51%\n",
      "anglez_240m_max           | 重要性: 0.014621 | 占比: 1.46%\n",
      "anglez_2m_std             | 重要性: 0.010243 | 占比: 1.02%\n",
      "anglez_1v_30m_mean        | 重要性: 0.007271 | 占比: 0.73%\n",
      "anglez_1v_15m_mean        | 重要性: 0.006557 | 占比: 0.66%\n",
      "anglez_1v_30m_std         | 重要性: 0.006034 | 占比: 0.60%\n",
      "anglez_120m_std           | 重要性: 0.005911 | 占比: 0.59%\n",
      "anglez_240m_std           | 重要性: 0.005770 | 占比: 0.58%\n",
      "anglez_1v_2m_mean         | 重要性: 0.004770 | 占比: 0.48%\n",
      "enmo_120m_mean            | 重要性: 0.004187 | 占比: 0.42%\n",
      "enmo_15m_mean             | 重要性: 0.004013 | 占比: 0.40%\n",
      "anglez_1v_120m_std        | 重要性: 0.003908 | 占比: 0.39%\n",
      "anglez_1v_3m_mean         | 重要性: 0.003361 | 占比: 0.34%\n",
      "anglez_1v_30m_max         | 重要性: 0.003132 | 占比: 0.31%\n",
      "enmo_1v_120m_max          | 重要性: 0.003044 | 占比: 0.30%\n",
      "anglez_1v_3m_std          | 重要性: 0.003033 | 占比: 0.30%\n",
      "enmo_1v_240m_mean         | 重要性: 0.003026 | 占比: 0.30%\n",
      "anglez_120m_max           | 重要性: 0.002752 | 占比: 0.28%\n",
      "anglez_1v_4m_mean         | 重要性: 0.002577 | 占比: 0.26%\n",
      "anglez_1v_240m_mean       | 重要性: 0.002445 | 占比: 0.24%\n",
      "anglez_1v_1m_std          | 重要性: 0.002343 | 占比: 0.23%\n",
      "anglez_1v_2m_max          | 重要性: 0.002301 | 占比: 0.23%\n",
      "enmo_1v_1m_max            | 重要性: 0.002176 | 占比: 0.22%\n",
      "enmo_30m_std              | 重要性: 0.002118 | 占比: 0.21%\n",
      "anglez_1v_5m_mean         | 重要性: 0.002023 | 占比: 0.20%\n",
      "anglez_1m_max             | 重要性: 0.001923 | 占比: 0.19%\n",
      "anglez_2m_mean            | 重要性: 0.001828 | 占比: 0.18%\n",
      "enmo_30m_mean             | 重要性: 0.001795 | 占比: 0.18%\n",
      "anglez_1v_60m_std         | 重要性: 0.001633 | 占比: 0.16%\n",
      "anglez_3m_mean            | 重要性: 0.001615 | 占比: 0.16%\n",
      "enmo_60m_mean             | 重要性: 0.001522 | 占比: 0.15%\n",
      "anglez_60m_std            | 重要性: 0.001482 | 占比: 0.15%\n",
      "enmo_120m_std             | 重要性: 0.001474 | 占比: 0.15%\n",
      "anglez_1v_15m_max         | 重要性: 0.001326 | 占比: 0.13%\n",
      "anglez_1v_10m_mean        | 重要性: 0.001259 | 占比: 0.13%\n",
      "enmo_10m_mean             | 重要性: 0.001249 | 占比: 0.12%\n",
      "anglez_15m_mean           | 重要性: 0.001193 | 占比: 0.12%\n",
      "anglez_4m_mean            | 重要性: 0.001078 | 占比: 0.11%\n",
      "anglez_3m_max             | 重要性: 0.000992 | 占比: 0.10%\n",
      "enmo_60m_std              | 重要性: 0.000853 | 占比: 0.09%\n",
      "anglez_3m_std             | 重要性: 0.000734 | 占比: 0.07%\n",
      "anglez_10m_mean           | 重要性: 0.000701 | 占比: 0.07%\n",
      "anglez_1v_5m_max          | 重要性: 0.000688 | 占比: 0.07%\n",
      "enmo_1v_5m_mean           | 重要性: 0.000647 | 占比: 0.06%\n",
      "enmo_1v_1m_std            | 重要性: 0.000595 | 占比: 0.06%\n",
      "anglez_1v_10m_std         | 重要性: 0.000540 | 占比: 0.05%\n",
      "enmo_1v_15m_max           | 重要性: 0.000491 | 占比: 0.05%\n",
      "enmo_4m_mean              | 重要性: 0.000346 | 占比: 0.03%\n",
      "enmo_1m_std               | 重要性: 0.000314 | 占比: 0.03%\n",
      "enmo_1v_3m_mean           | 重要性: 0.000207 | 占比: 0.02%\n",
      "enmo_1v_2m_mean           | 重要性: 0.000165 | 占比: 0.02%\n",
      "总重要性: 1.000000\n",
      "特征重要性已追加到 importance.csv\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "import os\n",
    "# 定义模型超参数字典\n",
    "model_params = {\n",
    "    'n_estimators': 10,              # 决策树数量（默认：100）\n",
    "    'criterion': 'gini',             # 分裂标准（默认：'gini'）\n",
    "    'max_depth': 20,                 # 树的最大深度（默认：None）\n",
    "    'min_samples_split': 2,          # 分裂所需的最小样本数（默认：2）\n",
    "    'min_samples_leaf': 100,         # 每个叶节点最少样本数（默认：1）\n",
    "    'min_weight_fraction_leaf': 0.0, # 叶节点最小权重分数（默认：0.0）\n",
    "    'max_features': 'sqrt',          # 寻找最佳分裂时考虑的特征数量（默认：'sqrt'）\n",
    "    'max_leaf_nodes': None,          # 最大叶节点数（默认：None）\n",
    "    'min_impurity_decrease': 0.0,    # 最小不纯度减少（默认：0.0）\n",
    "    'bootstrap': True,               # 是否使用bootstrap抽样（默认：True）\n",
    "    'oob_score': False,              # 是否使用袋外样本评估（默认：False）\n",
    "    'n_jobs': -1,                    # 使用所有CPU核心（默认：None）\n",
    "    'random_state': random_seed,     # 随机种子（默认：None）\n",
    "    'verbose': 0,                    # 详细程度（默认：0）\n",
    "    'warm_start': False,             # 是否使用上次的拟合结果作为起点（默认：False）\n",
    "    'class_weight':'balanced',     # 类别权重（默认：None）\n",
    "    'ccp_alpha': 0.0,                # 剪枝参数（默认：0.0）\n",
    "    'max_samples': None,             # bootstrap抽样的最大样本数（默认：None）\n",
    "    'monotonic_cst': None            # 单调约束（默认：None）\n",
    "}\n",
    "# 初始化随机森林分类器\n",
    "rf_classifier = RandomForestClassifier(random_state=model_params['random_state'])\n",
    "# 训练分类器（设置超参数）\n",
    "rf_classifier = RandomForestClassifier(**model_params)\n",
    "# 拟合模型\n",
    "rf_classifier.fit(X_train[feature_cols], y_train)\n",
    "# 获取特征重要性\n",
    "feature_importances = rf_classifier.feature_importances_\n",
    "total_importance = sum(feature_importances)\n",
    "# 准备数据\n",
    "importance_data = []\n",
    "print(\"特征重要性占比:\")\n",
    "for feature, importance in sorted(zip(feature_cols, feature_importances), \n",
    "                                 key=lambda x: x[1], reverse=True):\n",
    "    importance_ratio = (importance / total_importance) * 100\n",
    "    print(f\"{feature:25} | 重要性: {importance:.6f} | 占比: {importance_ratio:.2f}%\")\n",
    "    importance_data.append({\n",
    "        'feature': feature,\n",
    "        'importance': importance,\n",
    "        'importance_ratio': importance_ratio\n",
    "    })\n",
    "print(f\"总重要性: {total_importance:.6f}\")\n",
    "# 创建数据框\n",
    "importance_df = pd.DataFrame(importance_data)\n",
    "# 保存到CSV文件（追加模式）\n",
    "csv_file = 'importance.csv'\n",
    "if os.path.exists(csv_file):\n",
    "    # 文件存在，追加数据\n",
    "    importance_df.to_csv(csv_file, mode='a', header=False, index=False)\n",
    "    print(f\"特征重要性已追加到 {csv_file}\")\n",
    "else:\n",
    "    # 文件不存在，创建新文件\n",
    "    importance_df.to_csv(csv_file, index=False)\n",
    "    print(f\"特征重要性已保存到 {csv_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c002665c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 81/81 [00:06<00:00, 12.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "模型内存占用: 6.27 MB\n",
      "验证数据总天数: 2294\n",
      "预测天数: 1724\n",
      "预测率: 0.7515\n",
      "onset事件率: 0.9969\n",
      "wakeup事件率: 1.4965\n",
      "预测onset事件数: 2287\n",
      "预测wakeup事件数: 3433\n",
      "真实onset事件数: 1374\n",
      "真实wakeup事件数: 1374\n",
      "Onset匹配数(5/10/15/30/60/120)分钟：773/985/1130/1248/1314/1355\n",
      "Onset匹配率(5/10/15/30/60/120)分钟：0.5626/0.7169/0.8224/0.9083/0.9563/0.9862\n",
      "Onset平均差(秒)(5/10/15/30/60/120)分钟：155.92/216.35/283.54/378.83/487.88/708.21\n",
      "Onset标准差(秒)(5/10/15/30/60/120)分钟：71.93/138.35/219.77/369.97/596.09/1179.23\n",
      "\n",
      "Wakeup匹配数(5/10/15/30/60/120)分钟：322/626/788/1068/1255/1336\n",
      "Wakeup匹配率(5/10/15/30/60/120)分钟：0.2344/0.4556/0.5735/0.7773/0.9134/0.9723\n",
      "Wakeup平均差(秒)(5/10/15/30/60/120)分钟：199.39/313.07/401.52/636.47/904.44/1155.83\n",
      "Wakeup标准差(秒)(5/10/15/30/60/120)分钟：69.37/138.94/217.07/456.41/784.04/1260.59\n",
      "\n",
      "总和匹配数(5/10/15/30/60/120)分钟：1095/1611/1918/2316/2569/2691\n",
      "总和匹配率(5/10/15/30/60/120)分钟：0.3985/0.5862/0.6980/0.8428/0.9349/0.9793\n",
      "总和平均差(秒)(5/10/15/30/60/120)分钟：168.70/253.93/332.02/497.64/691.38/930.44\n",
      "总和标准差(秒)(5/10/15/30/60/120)分钟：73.89/146.38/226.24/431.64/724.84/1240.65\n",
      "\n",
      "Random forest score: 0.22123260331053016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhuangzhuohan/sleep_data/my_py/metric.py:433: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .groupby([event_column_name, 'tolerance'], group_keys=False).apply(\n"
     ]
    }
   ],
   "source": [
    "from my_py.metric import score  # 导入自定义的评分函数\n",
    "from my_py.model_analyzer import analyze_sleep_model_performance\n",
    "from my_py.my_funs import get_events_new\n",
    "# 在验证集上检查模型性能\n",
    "min_sleep_duration = 12*30\n",
    "rf_submission = get_events_new(val_data, rf_classifier, feature_cols, id_cols, min_sleep_duration)  # 生成验证集的预测事件\n",
    "# 调用函数，传入 rf_classifier 参数以计算内存\n",
    "performance_results = analyze_sleep_model_performance(\n",
    "    rf_submission=rf_submission,\n",
    "    ground_truth=val_solution,  # 使用 val_solution 作为真实事件数据\n",
    "    val_data=val_data,\n",
    "    val_ids=val_ids,\n",
    "    rf_classifier=rf_classifier,  # 传入训练好的分类器模型\n",
    "    min_sleep_duration=min_sleep_duration  # 可根据需要调整最小睡眠周期长度\n",
    ")\n",
    "# 计算模型得分\n",
    "rf_score = score(val_solution, rf_submission, tolerances, **column_names)\n",
    "print(f\"Random forest score: {rf_score}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
