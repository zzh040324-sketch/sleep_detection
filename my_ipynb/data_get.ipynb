{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c9fb426e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polars版本: 1.37.1\n",
      "\n",
      "=== 查看文件: /home/zhuangzhuohan/sleep_data/train_series.parquet ===\n",
      "\n",
      "计算文件总数据量...\n",
      "文件总数据量: 127946340 行\n",
      "\n",
      "提取前20000行数据...\n",
      "样本数据行数: 20000\n",
      "样本数据列数: 5\n",
      "\n",
      "=== 查看文件: /home/zhuangzhuohan/sleep_data/test_series.parquet ===\n",
      "\n",
      "计算文件总数据量...\n",
      "文件总数据量: 450 行\n",
      "\n",
      "提取前20000行数据...\n",
      "样本数据行数: 450\n",
      "样本数据列数: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_83565/257700852.py:22: DeprecationWarning: `pl.count()` is deprecated. Please use `pl.len()` instead.\n",
      "(Deprecated in version 0.20.5)\n",
      "  total_rows = lazy_df.select(pl.count()).collect()[0, 0]\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "import sys\n",
    "\n",
    "def inspect_parquet_file(file_path, sample_size=20000):\n",
    "    \"\"\"\n",
    "    查看parquet文件的数据格式并提取样本\n",
    "    \n",
    "    参数:\n",
    "    file_path: parquet文件路径\n",
    "    sample_size: 提取的样本大小\n",
    "    \n",
    "    返回:\n",
    "    sample: 提取的数据样本\n",
    "    \"\"\"\n",
    "    print(f\"\\n=== 查看文件: {file_path} ===\")\n",
    "    \n",
    "    # 使用lazy loading读取文件\n",
    "    lazy_df = pl.scan_parquet(file_path)\n",
    "    \n",
    "    # 计算文件总数据量（高效方法，不加载所有数据）\n",
    "    print(\"\\n计算文件总数据量...\")\n",
    "    total_rows = lazy_df.select(pl.count()).collect()[0, 0]\n",
    "    print(f\"文件总数据量: {total_rows} 行\")\n",
    "\n",
    "    # 提取样本数据\n",
    "    print(f\"\\n提取前{sample_size}行数据...\")\n",
    "    sample = lazy_df.head(sample_size).collect()\n",
    "    \n",
    "    # 打印样本信息\n",
    "    print(f\"样本数据行数: {len(sample)}\")\n",
    "    print(f\"样本数据列数: {len(sample.columns)}\")\n",
    "    \n",
    "    return sample\n",
    "\n",
    "def save_to_csv(df, file_path):\n",
    "    \"\"\"\n",
    "    保存DataFrame到CSV文件，兼容不同版本的Polars\n",
    "    \n",
    "    参数:\n",
    "    df: DataFrame对象\n",
    "    file_path: 保存路径\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 尝试使用to_csv方法\n",
    "        df.to_csv(file_path)\n",
    "        print(f\"成功保存到: {file_path}\")\n",
    "    except AttributeError:\n",
    "        # 如果to_csv方法不存在，尝试其他方法\n",
    "        print(\"to_csv方法不存在，尝试其他保存方式...\")\n",
    "        try:\n",
    "            # 尝试使用write_csv方法（旧版本Polars）\n",
    "            df.write_csv(file_path)\n",
    "            print(f\"成功保存到: {file_path}\")\n",
    "        except AttributeError:\n",
    "            # 如果还是失败，转换为Pandas DataFrame再保存\n",
    "            print(\"尝试转换为Pandas DataFrame后保存...\")\n",
    "            pd_df = df.to_pandas()\n",
    "            pd_df.to_csv(file_path, index=False)\n",
    "            print(f\"成功保存到: {file_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 打印Polars版本\n",
    "    print(f\"Polars版本: {pl.__version__}\")\n",
    "    \n",
    "    # 定义文件路径\n",
    "    train_file = \"/home/zhuangzhuohan/sleep_data/train_series.parquet\"\n",
    "    test_file = \"/home/zhuangzhuohan/sleep_data/test_series.parquet\"\n",
    "    \n",
    "    # 查看训练数据\n",
    "    train_sample = inspect_parquet_file(train_file)\n",
    "    \n",
    "    # 查看测试数据\n",
    "    test_sample = inspect_parquet_file(test_file)\n",
    "    \n",
    "    # 可选：保存样本为CSV文件以便后续查看\n",
    "    save_csv = input(\"\\n是否将样本保存为CSV文件？(y/n): \")\n",
    "    if save_csv.lower() == 'y':\n",
    "        save_to_csv(train_sample, \"/home/zhuangzhuohan/sleep_data/train_series_parquet_sample.csv\")\n",
    "        save_to_csv(test_sample, \"/home/zhuangzhuohan/sleep_data/test_series_parquet_sample.csv\")\n",
    "        print(\"样本已保存为CSV文件\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "70cb1424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始处理文件: /home/zhuangzhuohan/sleep_data/train_events.csv\n",
      "原始数据行数: 14508\n",
      "原始数据列数: 5\n",
      "\n",
      "各列空值情况:\n",
      "  series_id: 0 个空值\n",
      "  night: 0 个空值\n",
      "  event: 0 个空值\n",
      "  step: 4923 个空值\n",
      "  timestamp: 4923 个空值\n",
      "\n",
      "过滤后数据行数: 9585\n",
      "移除的行数: 4923\n",
      "\n",
      "过滤后的数据已保存到: /home/zhuangzhuohan/sleep_data/train_events_clean.csv\n",
      "\n",
      "过滤后的数据前5行:\n",
      "shape: (5, 5)\n",
      "┌──────────────┬───────┬────────┬───────┬──────────────────────────┐\n",
      "│ series_id    ┆ night ┆ event  ┆ step  ┆ timestamp                │\n",
      "│ ---          ┆ ---   ┆ ---    ┆ ---   ┆ ---                      │\n",
      "│ str          ┆ i64   ┆ str    ┆ i64   ┆ str                      │\n",
      "╞══════════════╪═══════╪════════╪═══════╪══════════════════════════╡\n",
      "│ 038441c925bb ┆ 1     ┆ onset  ┆ 4992  ┆ 2018-08-14T22:26:00-0400 │\n",
      "│ 038441c925bb ┆ 1     ┆ wakeup ┆ 10932 ┆ 2018-08-15T06:41:00-0400 │\n",
      "│ 038441c925bb ┆ 2     ┆ onset  ┆ 20244 ┆ 2018-08-15T19:37:00-0400 │\n",
      "│ 038441c925bb ┆ 2     ┆ wakeup ┆ 27492 ┆ 2018-08-16T05:41:00-0400 │\n",
      "│ 038441c925bb ┆ 3     ┆ onset  ┆ 39996 ┆ 2018-08-16T23:03:00-0400 │\n",
      "└──────────────┴───────┴────────┴───────┴──────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "def clean_train_events(input_file, output_file):\n",
    "    \"\"\"\n",
    "    清理train_events.csv文件，移除没有step和timestamp数据的行，不修改原始文件\n",
    "    \n",
    "    参数:\n",
    "    input_file: 输入文件路径\n",
    "    output_file: 输出文件路径\n",
    "    \"\"\"\n",
    "    print(f\"开始处理文件: {input_file}\")\n",
    "    \n",
    "    # 读取CSV文件（不修改原始文件）\n",
    "    df = pl.read_csv(input_file)\n",
    "    \n",
    "    # 打印原始数据信息\n",
    "    print(f\"原始数据行数: {len(df)}\")\n",
    "    print(f\"原始数据列数: {len(df.columns)}\")\n",
    "    \n",
    "    # 检查每列的空值情况\n",
    "    print(\"\\n各列空值情况:\")\n",
    "    for col in df.columns:\n",
    "        null_count = df[col].is_null().sum()\n",
    "        print(f\"  {col}: {null_count} 个空值\")\n",
    "    \n",
    "    # 过滤掉step或timestamp为空的行\n",
    "    filtered_df = df.filter(\n",
    "        pl.col('step').is_not_null() & pl.col('timestamp').is_not_null()\n",
    "    )\n",
    "    \n",
    "    # 打印过滤后的数据信息\n",
    "    print(f\"\\n过滤后数据行数: {len(filtered_df)}\")\n",
    "    print(f\"移除的行数: {len(df) - len(filtered_df)}\")\n",
    "    \n",
    "    # 保存过滤后的数据到新文件（不修改原始文件）\n",
    "    filtered_df.write_csv(output_file)\n",
    "    print(f\"\\n过滤后的数据已保存到: {output_file}\")\n",
    "    \n",
    "    # 打印前5行数据，确认格式正确\n",
    "    print(\"\\n过滤后的数据前5行:\")\n",
    "    print(filtered_df.head())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 定义文件路径\n",
    "    input_file = \"/home/zhuangzhuohan/sleep_data/train_events.csv\"\n",
    "    output_file = \"/home/zhuangzhuohan/sleep_data/train_events_clean.csv\"\n",
    "    \n",
    "    # 执行清理操作\n",
    "    clean_train_events(input_file, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6b80527a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始处理文件: /home/zhuangzhuohan/sleep_data/train_events_clean.csv\n",
      "原始数据行数: 9585\n",
      "原始数据列数: 5\n",
      "\n",
      "处理后的数据已保存到: /home/zhuangzhuohan/sleep_data/train_events_clean_no_timezone.csv\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "def remove_timezone_from_timestamp(input_file, output_file):\n",
    "    \"\"\"\n",
    "    移除train_events_clean.csv文件中timestamp字段的时区信息\n",
    "    \n",
    "    参数:\n",
    "    input_file: 输入文件路径\n",
    "    output_file: 输出文件路径\n",
    "    \"\"\"\n",
    "    print(f\"开始处理文件: {input_file}\")\n",
    "    \n",
    "    # 读取CSV文件\n",
    "    df = pl.read_csv(input_file)\n",
    "    \n",
    "    # 打印原始数据信息\n",
    "    print(f\"原始数据行数: {len(df)}\")\n",
    "    print(f\"原始数据列数: {len(df.columns)}\")\n",
    "    \n",
    "    # 处理timestamp字段，去除时区信息\n",
    "    # 方法: 使用字符串替换，移除末尾的时区信息\n",
    "    processed_df = df.with_columns(\n",
    "        pl.col('timestamp').str.replace(r'[-+]\\d{4}$', '').alias('timestamp')\n",
    "    )\n",
    "    \n",
    "    # 保存处理后的数据到新文件\n",
    "    processed_df.write_csv(output_file)\n",
    "    print(f\"\\n处理后的数据已保存到: {output_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 定义文件路径\n",
    "    input_file = \"/home/zhuangzhuohan/sleep_data/train_events_clean.csv\"\n",
    "    output_file = \"/home/zhuangzhuohan/sleep_data/train_events_clean_no_timezone.csv\"\n",
    "    \n",
    "    # 执行处理操作\n",
    "    remove_timezone_from_timestamp(input_file, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "261d95ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 处理训练数据 ===\n",
      "开始处理文件: /home/zhuangzhuohan/sleep_data/train_series.parquet\n",
      "文件架构:\n",
      "  series_id: String\n",
      "  step: UInt32\n",
      "  timestamp: String\n",
      "  anglez: Float32\n",
      "  enmo: Float32\n",
      "文件总数据量: 127946340 行\n",
      "处理数据并保存...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_83565/3794346865.py:23: DeprecationWarning: `pl.count()` is deprecated. Please use `pl.len()` instead.\n",
      "(Deprecated in version 0.20.5)\n",
      "  total_rows = lazy_df.select(pl.count()).collect()[0, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "处理后的数据已保存到: /home/zhuangzhuohan/sleep_data/train_series_no_timezone.parquet\n",
      "\n",
      "=== 处理测试数据 ===\n",
      "开始处理文件: /home/zhuangzhuohan/sleep_data/test_series.parquet\n",
      "文件架构:\n",
      "  series_id: String\n",
      "  step: UInt32\n",
      "  timestamp: String\n",
      "  anglez: Float32\n",
      "  enmo: Float32\n",
      "文件总数据量: 450 行\n",
      "处理数据并保存...\n",
      "\n",
      "处理后的数据已保存到: /home/zhuangzhuohan/sleep_data/test_series_no_timezone.parquet\n",
      "\n",
      "所有文件处理完成！\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "def remove_timezone_from_parquet(input_file, output_file):\n",
    "    \"\"\"\n",
    "    移除parquet文件中timestamp字段的时区信息\n",
    "    \n",
    "    参数:\n",
    "    input_file: 输入parquet文件路径\n",
    "    output_file: 输出parquet文件路径\n",
    "    \"\"\"\n",
    "    print(f\"开始处理文件: {input_file}\")\n",
    "    \n",
    "    # 使用lazy loading读取parquet文件\n",
    "    lazy_df = pl.scan_parquet(input_file)\n",
    "    \n",
    "    # 获取文件架构\n",
    "    schema = lazy_df.collect_schema()\n",
    "    print(\"文件架构:\")\n",
    "    for col_name, col_type in schema.items():\n",
    "        print(f\"  {col_name}: {col_type}\")\n",
    "    \n",
    "    # 计算文件总数据量\n",
    "    total_rows = lazy_df.select(pl.count()).collect()[0, 0]\n",
    "    print(f\"文件总数据量: {total_rows} 行\")\n",
    "    \n",
    "    # 处理数据，移除时区信息\n",
    "    # 使用正则表达式替换掉末尾的时区信息（如-0400, +0530等）\n",
    "    processed_lazy_df = lazy_df.with_columns(\n",
    "        pl.col('timestamp').str.replace(r'[-+]\\d{4}$', '').alias('timestamp')\n",
    "    )\n",
    "    \n",
    "    # 收集并保存处理后的数据\n",
    "    print(\"处理数据并保存...\")\n",
    "    processed_df = processed_lazy_df.collect()\n",
    "    processed_df.write_parquet(output_file)\n",
    "    \n",
    "    print(f\"\\n处理后的数据已保存到: {output_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 定义文件路径\n",
    "    train_input = \"/home/zhuangzhuohan/sleep_data/train_series.parquet\"\n",
    "    train_output = \"/home/zhuangzhuohan/sleep_data/train_series_no_timezone.parquet\"\n",
    "    \n",
    "    test_input = \"/home/zhuangzhuohan/sleep_data/test_series.parquet\"\n",
    "    test_output = \"/home/zhuangzhuohan/sleep_data/test_series_no_timezone.parquet\"\n",
    "    \n",
    "    # 处理训练数据\n",
    "    print(\"=== 处理训练数据 ===\")\n",
    "    remove_timezone_from_parquet(train_input, train_output)\n",
    "    \n",
    "    # 处理测试数据\n",
    "    print(\"\\n=== 处理测试数据 ===\")\n",
    "    remove_timezone_from_parquet(test_input, test_output)\n",
    "    \n",
    "    print(\"\\n所有文件处理完成！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e7ea17a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polars版本: 1.37.1\n",
      "\n",
      "=== 查看文件: /home/zhuangzhuohan/sleep_data/train_series_no_timezone.parquet ===\n",
      "\n",
      "计算文件总数据量...\n",
      "文件总数据量: 127946340 行\n",
      "\n",
      "提取前20000行数据...\n",
      "样本数据行数: 20000\n",
      "样本数据列数: 5\n",
      "\n",
      "=== 查看文件: /home/zhuangzhuohan/sleep_data/test_series_no_timezone.parquet ===\n",
      "\n",
      "计算文件总数据量...\n",
      "文件总数据量: 450 行\n",
      "\n",
      "提取前20000行数据...\n",
      "样本数据行数: 450\n",
      "样本数据列数: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_83565/2975673865.py:22: DeprecationWarning: `pl.count()` is deprecated. Please use `pl.len()` instead.\n",
      "(Deprecated in version 0.20.5)\n",
      "  total_rows = lazy_df.select(pl.count()).collect()[0, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to_csv方法不存在，尝试其他保存方式...\n",
      "成功保存到: /home/zhuangzhuohan/sleep_data/train_series_no_timezone_parquet_sample.csv\n",
      "to_csv方法不存在，尝试其他保存方式...\n",
      "成功保存到: /home/zhuangzhuohan/sleep_data/test_series_no_timezone_parquet_sample.csv\n",
      "样本已保存为CSV文件\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "import sys\n",
    "\n",
    "def inspect_parquet_file(file_path, sample_size=20000):\n",
    "    \"\"\"\n",
    "    查看parquet文件的数据格式并提取样本\n",
    "    \n",
    "    参数:\n",
    "    file_path: parquet文件路径\n",
    "    sample_size: 提取的样本大小\n",
    "    \n",
    "    返回:\n",
    "    sample: 提取的数据样本\n",
    "    \"\"\"\n",
    "    print(f\"\\n=== 查看文件: {file_path} ===\")\n",
    "    \n",
    "    # 使用lazy loading读取文件\n",
    "    lazy_df = pl.scan_parquet(file_path)\n",
    "    \n",
    "    # 计算文件总数据量（高效方法，不加载所有数据）\n",
    "    print(\"\\n计算文件总数据量...\")\n",
    "    total_rows = lazy_df.select(pl.count()).collect()[0, 0]\n",
    "    print(f\"文件总数据量: {total_rows} 行\")\n",
    "\n",
    "    # 提取样本数据\n",
    "    print(f\"\\n提取前{sample_size}行数据...\")\n",
    "    sample = lazy_df.head(sample_size).collect()\n",
    "    \n",
    "    # 打印样本信息\n",
    "    print(f\"样本数据行数: {len(sample)}\")\n",
    "    print(f\"样本数据列数: {len(sample.columns)}\")\n",
    "    \n",
    "    return sample\n",
    "\n",
    "def save_to_csv(df, file_path):\n",
    "    \"\"\"\n",
    "    保存DataFrame到CSV文件，兼容不同版本的Polars\n",
    "    \n",
    "    参数:\n",
    "    df: DataFrame对象\n",
    "    file_path: 保存路径\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 尝试使用to_csv方法\n",
    "        df.to_csv(file_path)\n",
    "        print(f\"成功保存到: {file_path}\")\n",
    "    except AttributeError:\n",
    "        # 如果to_csv方法不存在，尝试其他方法\n",
    "        print(\"to_csv方法不存在，尝试其他保存方式...\")\n",
    "        try:\n",
    "            # 尝试使用write_csv方法（旧版本Polars）\n",
    "            df.write_csv(file_path)\n",
    "            print(f\"成功保存到: {file_path}\")\n",
    "        except AttributeError:\n",
    "            # 如果还是失败，转换为Pandas DataFrame再保存\n",
    "            print(\"尝试转换为Pandas DataFrame后保存...\")\n",
    "            pd_df = df.to_pandas()\n",
    "            pd_df.to_csv(file_path, index=False)\n",
    "            print(f\"成功保存到: {file_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 打印Polars版本\n",
    "    print(f\"Polars版本: {pl.__version__}\")\n",
    "    \n",
    "    # 定义文件路径\n",
    "    train_file = \"/home/zhuangzhuohan/sleep_data/train_series_no_timezone.parquet\"\n",
    "    test_file = \"/home/zhuangzhuohan/sleep_data/test_series_no_timezone.parquet\"\n",
    "    \n",
    "    # 查看训练数据\n",
    "    train_sample = inspect_parquet_file(train_file)\n",
    "    \n",
    "    # 查看测试数据\n",
    "    test_sample = inspect_parquet_file(test_file)\n",
    "    \n",
    "    # 可选：保存样本为CSV文件以便后续查看\n",
    "    save_csv = input(\"\\n是否将样本保存为CSV文件？(y/n): \")\n",
    "    if save_csv.lower() == 'y':\n",
    "        save_to_csv(train_sample, \"/home/zhuangzhuohan/sleep_data/train_series_no_timezone_parquet_sample.csv\")\n",
    "        save_to_csv(test_sample, \"/home/zhuangzhuohan/sleep_data/test_series_no_timezone_parquet_sample.csv\")\n",
    "        print(\"样本已保存为CSV文件\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1c5f64f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始验证文件: /home/zhuangzhuohan/sleep_data/train_series_no_timezone.parquet\n",
      "文件总数据量: 127946340 行\n",
      "包含时区信息的行数: 0\n",
      "不包含时区信息的行数: 127946340\n",
      "\n",
      "✓ 所有timestamp数据都已成功移除时区信息!\n",
      "\n",
      "处理后的timestamp示例:\n",
      "shape: (5, 1)\n",
      "┌─────────────────────┐\n",
      "│ timestamp           │\n",
      "│ ---                 │\n",
      "│ str                 │\n",
      "╞═════════════════════╡\n",
      "│ 2018-08-14T15:30:00 │\n",
      "│ 2018-08-14T15:30:05 │\n",
      "│ 2018-08-14T15:30:10 │\n",
      "│ 2018-08-14T15:30:15 │\n",
      "│ 2018-08-14T15:30:20 │\n",
      "└─────────────────────┘\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_83565/695088220.py:16: DeprecationWarning: `pl.count()` is deprecated. Please use `pl.len()` instead.\n",
      "(Deprecated in version 0.20.5)\n",
      "  total_rows = lazy_df.select(pl.count()).collect()[0, 0]\n",
      "/tmp/ipykernel_83565/695088220.py:26: DeprecationWarning: `pl.count()` is deprecated. Please use `pl.len()` instead.\n",
      "(Deprecated in version 0.20.5)\n",
      "  ).select(pl.count()).collect()[0, 0]\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "def validate_timezone_removal(input_file):\n",
    "    \"\"\"\n",
    "    验证parquet文件中所有timestamp数据是否都去掉了时区\n",
    "    \n",
    "    参数:\n",
    "    input_file: 输入parquet文件路径\n",
    "    \"\"\"\n",
    "    print(f\"开始验证文件: {input_file}\")\n",
    "    \n",
    "    # 使用lazy loading读取parquet文件\n",
    "    lazy_df = pl.scan_parquet(input_file)\n",
    "    \n",
    "    # 获取文件总数据量\n",
    "    total_rows = lazy_df.select(pl.count()).collect()[0, 0]\n",
    "    print(f\"文件总数据量: {total_rows} 行\")\n",
    "    \n",
    "    # 定义时区模式的正则表达式\n",
    "    timezone_pattern = r'[-+]\\d{4}$'\n",
    "    \n",
    "    # 检查是否存在时区信息\n",
    "    # 方法: 计算包含时区模式的行数\n",
    "    timezone_count = lazy_df.filter(\n",
    "        pl.col('timestamp').str.contains(timezone_pattern)\n",
    "    ).select(pl.count()).collect()[0, 0]\n",
    "    \n",
    "    # 打印验证结果\n",
    "    print(f\"包含时区信息的行数: {timezone_count}\")\n",
    "    print(f\"不包含时区信息的行数: {total_rows - timezone_count}\")\n",
    "    \n",
    "    # 如果存在包含时区信息的行，打印前5个例子\n",
    "    if timezone_count > 0:\n",
    "        print(\"\\n包含时区信息的前5个例子:\")\n",
    "        timezone_examples = lazy_df.filter(\n",
    "            pl.col('timestamp').str.contains(timezone_pattern)\n",
    "        ).select('timestamp').head().collect()\n",
    "        print(timezone_examples)\n",
    "    else:\n",
    "        print(\"\\n✓ 所有timestamp数据都已成功移除时区信息!\")\n",
    "    \n",
    "    # 打印一些处理后的timestamp示例，确认格式正确\n",
    "    print(\"\\n处理后的timestamp示例:\")\n",
    "    examples = lazy_df.select('timestamp').head().collect()\n",
    "    print(examples)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 定义文件路径\n",
    "    input_file = \"/home/zhuangzhuohan/sleep_data/train_series_no_timezone.parquet\"\n",
    "    \n",
    "    # 执行验证\n",
    "    validate_timezone_removal(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3b20017d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始处理数据...\n",
      "读取train_events_clean_no_timezone.csv中的series_id...\n",
      "train_events_clean_no_timezone.csv中的series_id数量: 269\n",
      "读取train_series_no_timezone.parquet中的series_id...\n",
      "train_series_no_timezone.parquet中的series_id数量: 277\n",
      "找出差异的series_id...\n",
      "train_series中有但train_events中没有的series_id数量: 8\n",
      "这些series_id是:\n",
      "shape: (8, 1)\n",
      "┌──────────────┐\n",
      "│ series_id    │\n",
      "│ ---          │\n",
      "│ str          │\n",
      "╞══════════════╡\n",
      "│ 2fc653ca75c7 │\n",
      "│ e11b9d69f856 │\n",
      "│ 89c7daa72eee │\n",
      "│ a3e59c2ce3f6 │\n",
      "│ c7b1283bb7eb │\n",
      "│ c5d08fc3e040 │\n",
      "│ 0f9e60a8e56d │\n",
      "│ 390b487231ce │\n",
      "└──────────────┘\n",
      "过滤train_series数据...\n",
      "计算数据量...\n",
      "过滤前数据行数: 127946340\n",
      "过滤后数据行数: 124822080\n",
      "移除的数据行数: 3124260\n",
      "保存过滤后的数据...\n",
      "新文件已保存到: /home/zhuangzhuohan/sleep_data/train_series_new_no_timezone.parquet\n",
      "验证新文件...\n",
      "新文件中的series_id数量: 269\n",
      "新文件中的数据行数: 124822080\n",
      "\n",
      "处理完成!\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "def filter_train_series_by_events():\n",
    "    \"\"\"\n",
    "    找出train_events_clean_no_timezone.csv中没有但train_series_no_timezone.parquet中有的series_id\n",
    "    并从train_series_no_timezone.parquet中移除这些series_id对应的数据，生成新文件\n",
    "    \"\"\"\n",
    "    print(\"开始处理数据...\")\n",
    "    \n",
    "    # 定义文件路径\n",
    "    train_series_path = \"/home/zhuangzhuohan/sleep_data/train_series_no_timezone.parquet\"\n",
    "    train_events_path = \"/home/zhuangzhuohan/sleep_data/train_events_clean_no_timezone.csv\"\n",
    "    output_path = \"/home/zhuangzhuohan/sleep_data/train_series_new_no_timezone.parquet\"\n",
    "    \n",
    "    # 1. 读取train_events_clean_no_timezone.csv中的series_id\n",
    "    print(\"读取train_events_clean_no_timezone.csv中的series_id...\")\n",
    "    train_events = pl.read_csv(train_events_path)\n",
    "    events_series_ids = train_events.select('series_id').unique()\n",
    "    print(f\"train_events_clean_no_timezone.csv中的series_id数量: {len(events_series_ids)}\")\n",
    "    \n",
    "    # 2. 读取train_series_no_timezone.parquet中的series_id\n",
    "    print(\"读取train_series_no_timezone.parquet中的series_id...\")\n",
    "    train_series = pl.scan_parquet(train_series_path)\n",
    "    series_series_ids = train_series.select('series_id').unique().collect()\n",
    "    print(f\"train_series_no_timezone.parquet中的series_id数量: {len(series_series_ids)}\")\n",
    "    \n",
    "    # 3. 找出train_series中有但train_events中没有的series_id\n",
    "    print(\"找出差异的series_id...\")\n",
    "    # 使用anti join找出只在train_series中存在的series_id\n",
    "    diff_series_ids = series_series_ids.join(\n",
    "        events_series_ids,\n",
    "        on='series_id',\n",
    "        how='anti'\n",
    "    )\n",
    "    print(f\"train_series中有但train_events中没有的series_id数量: {len(diff_series_ids)}\")\n",
    "    print(\"这些series_id是:\")\n",
    "    print(diff_series_ids)\n",
    "    \n",
    "    # 4. 从train_series中过滤掉这些差异的series_id\n",
    "    print(\"过滤train_series数据...\")\n",
    "    # 先获取需要保留的series_id列表\n",
    "    keep_series_ids = events_series_ids.to_series().to_list()\n",
    "    # 过滤数据\n",
    "    filtered_train_series = train_series.filter(\n",
    "        pl.col('series_id').is_in(keep_series_ids)\n",
    "    )\n",
    "    \n",
    "    # 5. 计算过滤前后的数据量\n",
    "    print(\"计算数据量...\")\n",
    "    before_count = train_series.select(pl.len()).collect()[0, 0]\n",
    "    after_count = filtered_train_series.select(pl.len()).collect()[0, 0]\n",
    "    print(f\"过滤前数据行数: {before_count}\")\n",
    "    print(f\"过滤后数据行数: {after_count}\")\n",
    "    print(f\"移除的数据行数: {before_count - after_count}\")\n",
    "    \n",
    "    # 6. 将过滤后的数据保存为新文件\n",
    "    print(\"保存过滤后的数据...\")\n",
    "    filtered_train_series.sink_parquet(output_path)\n",
    "    print(f\"新文件已保存到: {output_path}\")\n",
    "    \n",
    "    # 7. 验证新文件\n",
    "    print(\"验证新文件...\")\n",
    "    new_train_series = pl.scan_parquet(output_path)\n",
    "    new_series_ids = new_train_series.select('series_id').unique().collect()\n",
    "    print(f\"新文件中的series_id数量: {len(new_series_ids)}\")\n",
    "    print(f\"新文件中的数据行数: {new_train_series.select(pl.len()).collect()[0, 0]}\")\n",
    "    \n",
    "    print(\"\\n处理完成!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    filter_train_series_by_events()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1f91856b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始统计所有文件中的series_id数量...\n",
      "\n",
      "统计 train_series_no_timezone 中的series_id数量:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  唯一series_id数量: 277\n",
      "\n",
      "统计 train_events_clean_no_timezone 中的series_id数量:\n",
      "  唯一series_id数量: 269\n",
      "\n",
      "统计 test_series_no_timezone 中的series_id数量:\n",
      "  唯一series_id数量: 3\n",
      "\n",
      "统计 train_series_original 中的series_id数量:\n",
      "  唯一series_id数量: 277\n",
      "\n",
      "统计 train_events_original 中的series_id数量:\n",
      "  唯一series_id数量: 277\n",
      "\n",
      "统计 test_series_original 中的series_id数量:\n",
      "  唯一series_id数量: 3\n",
      "\n",
      "统计 train_series_new 中的series_id数量:\n",
      "  唯一series_id数量: 269\n",
      "\n",
      "统计完成!\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "def count_series_ids_in_all_files():\n",
    "    \"\"\"\n",
    "    查看多个文件中series_id的数量\n",
    "    \"\"\"\n",
    "    print(\"开始统计所有文件中的series_id数量...\")\n",
    "    \n",
    "    # 定义文件路径\n",
    "    files = {\n",
    "        \"train_series_no_timezone\": \"/home/zhuangzhuohan/sleep_data/train_series_no_timezone.parquet\",\n",
    "        \"train_events_clean_no_timezone\": \"/home/zhuangzhuohan/sleep_data/train_events_clean_no_timezone.csv\",\n",
    "        \"test_series_no_timezone\": \"/home/zhuangzhuohan/sleep_data/test_series_no_timezone.parquet\",\n",
    "        \"train_series_original\": \"/home/zhuangzhuohan/sleep_data/train_series.parquet\",\n",
    "        \"train_events_original\": \"/home/zhuangzhuohan/sleep_data/train_events.csv\",\n",
    "        \"test_series_original\": \"/home/zhuangzhuohan/sleep_data/test_series.parquet\",\n",
    "        \"train_series_new\": \"/home/zhuangzhuohan/sleep_data/train_series_new_no_timezone.parquet\"\n",
    "    }\n",
    "    \n",
    "    # 统计每个文件的series_id数量\n",
    "    for name, path in files.items():\n",
    "        print(f\"\\n统计 {name} 中的series_id数量:\")\n",
    "        \n",
    "        try:\n",
    "            if path.endswith('.parquet'):\n",
    "                # 读取parquet文件\n",
    "                df = pl.scan_parquet(path)\n",
    "                count = df.select('series_id').unique().collect()\n",
    "            else:\n",
    "                # 读取csv文件\n",
    "                df = pl.read_csv(path)\n",
    "                count = df.select('series_id').unique()\n",
    "            \n",
    "            print(f\"  唯一series_id数量: {len(count)}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  错误: {str(e)}\")\n",
    "    \n",
    "    print(\"\\n统计完成!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    count_series_ids_in_all_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "732e4377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始检查series_id一致性...\n",
      "读取train_series_new_no_timezone.parquet...\n",
      "train_series_new_no_timezone中的唯一series_id数量: 269\n",
      "读取train_events_clean_no_timezone.csv...\n",
      "train_events_clean_no_timezone中的唯一series_id数量: 269\n",
      "\n",
      "检查train_series中的series_id是否都在train_events中存在:\n",
      "  ✓ 所有train_series中的series_id都在train_events中存在\n",
      "\n",
      "检查train_events中的series_id是否都在train_series中存在:\n",
      "  ✓ 所有train_events中的series_id都在train_series中存在\n",
      "\n",
      "共同存在的series_id数量: 269\n",
      "\n",
      "检查完成!\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "def check_series_id_consistency():\n",
    "    \"\"\"\n",
    "    检查train_series_new_no_timezone.parquet和train_events_clean_no_timezone.csv中\n",
    "    每个series_id是否都在另一个文件中存在\n",
    "    \"\"\"\n",
    "    print(\"开始检查series_id一致性...\")\n",
    "    \n",
    "    # 定义文件路径\n",
    "    train_series_path = \"/home/zhuangzhuohan/sleep_data/train_series_new_no_timezone.parquet\"\n",
    "    train_events_path = \"/home/zhuangzhuohan/sleep_data/train_events_clean_no_timezone.csv\"\n",
    "    \n",
    "    # 1. 读取train_series_new_no_timezone.parquet中的series_id\n",
    "    print(\"读取train_series_new_no_timezone.parquet...\")\n",
    "    train_series = pl.scan_parquet(train_series_path)\n",
    "    series_ids = train_series.select('series_id').unique().collect()\n",
    "    print(f\"train_series_new_no_timezone中的唯一series_id数量: {len(series_ids)}\")\n",
    "    \n",
    "    # 2. 读取train_events_clean_no_timezone.csv中的series_id\n",
    "    print(\"读取train_events_clean_no_timezone.csv...\")\n",
    "    train_events = pl.read_csv(train_events_path)\n",
    "    events_ids = train_events.select('series_id').unique()\n",
    "    print(f\"train_events_clean_no_timezone中的唯一series_id数量: {len(events_ids)}\")\n",
    "    \n",
    "    # 3. 检查train_series中的series_id是否都在train_events中存在\n",
    "    print(\"\\n检查train_series中的series_id是否都在train_events中存在:\")\n",
    "    series_only = series_ids.join(events_ids, on='series_id', how='anti')\n",
    "    if len(series_only) > 0:\n",
    "        print(f\"  发现 {len(series_only)} 个series_id只在train_series中存在:\")\n",
    "        print(series_only)\n",
    "    else:\n",
    "        print(\"  ✓ 所有train_series中的series_id都在train_events中存在\")\n",
    "    \n",
    "    # 4. 检查train_events中的series_id是否都在train_series中存在\n",
    "    print(\"\\n检查train_events中的series_id是否都在train_series中存在:\")\n",
    "    events_only = events_ids.join(series_ids, on='series_id', how='anti')\n",
    "    if len(events_only) > 0:\n",
    "        print(f\"  发现 {len(events_only)} 个series_id只在train_events中存在:\")\n",
    "        print(events_only)\n",
    "    else:\n",
    "        print(\"  ✓ 所有train_events中的series_id都在train_series中存在\")\n",
    "    \n",
    "    # 5. 检查共同存在的series_id数量\n",
    "    common_ids = series_ids.join(events_ids, on='series_id', how='inner')\n",
    "    print(f\"\\n共同存在的series_id数量: {len(common_ids)}\")\n",
    "    \n",
    "    print(\"\\n检查完成!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    check_series_id_consistency()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dfa2c809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始验证事件交替性...\n",
      "按series_id和night分组并排序...\n",
      "验证每个分组的事件交替性...\n",
      "\n",
      "验证完成! 总共检查了 4795 个夜晚的事件序列\n",
      "✗ 发现 5 个问题:\n",
      "  series_id: 44a41bba1ee7, night: 10, 问题: 事件数量不匹配: onset=0, wakeup=1\n",
      "  series_id: efbfc4526d58, night: 7, 问题: 事件数量不匹配: onset=0, wakeup=1\n",
      "  series_id: 154fe824ed87, night: 30, 问题: 事件数量不匹配: onset=0, wakeup=1\n",
      "  series_id: 0ce74d6d2106, night: 20, 问题: 事件数量不匹配: onset=1, wakeup=0\n",
      "  series_id: f8a8da8bdd00, night: 17, 问题: 事件数量不匹配: onset=0, wakeup=1\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "def validate_event_alternation():\n",
    "    \"\"\"\n",
    "    验证train_events_clean_no_timezone.csv中onset和wakeup事件的交替性\n",
    "    1. 检查每个series_id和night分组中onset和wakeup数量是否相等\n",
    "    2. 检查事件是否交替出现（onset后是wakeup，wakeup后是onset）\n",
    "    \"\"\"\n",
    "    print(\"开始验证事件交替性...\")\n",
    "    \n",
    "    # 定义文件路径\n",
    "    file_path = \"/home/zhuangzhuohan/sleep_data/train_events_clean_no_timezone.csv\"\n",
    "    \n",
    "    # 读取文件\n",
    "    train_events = pl.read_csv(file_path)\n",
    "    \n",
    "    # 确保必要的列存在\n",
    "    required_cols = ['series_id', 'night', 'event', 'timestamp']\n",
    "    for col in required_cols:\n",
    "        if col not in train_events.columns:\n",
    "            print(f\"错误: 文件中不存在{col}列!\")\n",
    "            return\n",
    "    \n",
    "    # 转换timestamp为datetime类型\n",
    "    train_events = train_events.with_columns(\n",
    "        pl.col('timestamp').str.to_datetime()\n",
    "    )\n",
    "    \n",
    "    # 按series_id、night分组，并按timestamp排序\n",
    "    print(\"按series_id和night分组并排序...\")\n",
    "    grouped_events = train_events.group_by(['series_id', 'night']).agg([\n",
    "        pl.col('event').sort_by('timestamp').alias('sorted_events')\n",
    "    ])\n",
    "    \n",
    "    # 验证每个分组\n",
    "    print(\"验证每个分组的事件交替性...\")\n",
    "    issues = []\n",
    "    \n",
    "    for row in grouped_events.iter_rows(named=True):\n",
    "        series_id = row['series_id']\n",
    "        night = row['night']\n",
    "        events = row['sorted_events']\n",
    "        \n",
    "        # 检查1: onset和wakeup数量是否相等\n",
    "        onset_count = events.count('onset')\n",
    "        wakeup_count = events.count('wakeup')\n",
    "        \n",
    "        if onset_count != wakeup_count:\n",
    "            issues.append({\n",
    "                'series_id': series_id,\n",
    "                'night': night,\n",
    "                'issue': f'事件数量不匹配: onset={onset_count}, wakeup={wakeup_count}'\n",
    "            })\n",
    "            continue\n",
    "        \n",
    "        # 检查2: 事件是否交替出现\n",
    "        valid_sequence = True\n",
    "        for i, event in enumerate(events):\n",
    "            if i == 0:\n",
    "                # 第一个事件应该是onset\n",
    "                if event != 'onset':\n",
    "                    valid_sequence = False\n",
    "                    issues.append({\n",
    "                        'series_id': series_id,\n",
    "                        'night': night,\n",
    "                        'issue': f'第一个事件应该是onset，实际是{event}'\n",
    "                    })\n",
    "                    break\n",
    "            else:\n",
    "                # 检查事件交替\n",
    "                prev_event = events[i-1]\n",
    "                if (prev_event == 'onset' and event != 'wakeup') or \\\n",
    "                   (prev_event == 'wakeup' and event != 'onset'):\n",
    "                    valid_sequence = False\n",
    "                    issues.append({\n",
    "                        'series_id': series_id,\n",
    "                        'night': night,\n",
    "                        'issue': f'事件交替错误: {prev_event}后应该是{[\"wakeup\" if prev_event == \"onset\" else \"onset\"][0]}，实际是{event}'\n",
    "                    })\n",
    "                    break\n",
    "    \n",
    "    # 输出验证结果\n",
    "    print(f\"\\n验证完成! 总共检查了 {len(grouped_events)} 个夜晚的事件序列\")\n",
    "    \n",
    "    if len(issues) == 0:\n",
    "        print(\"✓ 所有事件序列都符合要求:\")\n",
    "        print(\"  - 每个夜晚的onset和wakeup数量相等\")\n",
    "        print(\"  - 事件交替出现（onset后是wakeup，wakeup后是onset）\")\n",
    "        print(\"  - 每个夜晚以onset开始，以wakeup结束\")\n",
    "    else:\n",
    "        print(f\"✗ 发现 {len(issues)} 个问题:\")\n",
    "        for issue in issues[:10]:  # 只显示前10个问题\n",
    "            print(f\"  series_id: {issue['series_id']}, night: {issue['night']}, 问题: {issue['issue']}\")\n",
    "        \n",
    "        if len(issues) > 10:\n",
    "            print(f\"  ... 还有 {len(issues) - 10} 个问题未显示\")\n",
    "    \n",
    "    return len(issues) == 0\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    validate_event_alternation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "115f01e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始验证事件交替性...\n",
      "按series_id和night分组并排序...\n",
      "验证每个分组的事件交替性...\n",
      "\n",
      "验证完成! 总共检查了 4790 个夜晚的事件序列\n",
      "✓ 所有事件序列都符合要求:\n",
      "  - 每个夜晚的onset和wakeup数量相等\n",
      "  - 事件交替出现（onset后是wakeup，wakeup后是onset）\n",
      "  - 每个夜晚以onset开始，以wakeup结束\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "def validate_event_alternation():\n",
    "    \"\"\"\n",
    "    验证train_events_clean_no_timezone.csv中onset和wakeup事件的交替性\n",
    "    1. 检查每个series_id和night分组中onset和wakeup数量是否相等\n",
    "    2. 检查事件是否交替出现（onset后是wakeup，wakeup后是onset）\n",
    "    \"\"\"\n",
    "    print(\"开始验证事件交替性...\")\n",
    "    \n",
    "    # 定义文件路径\n",
    "    file_path = \"/home/zhuangzhuohan/sleep_data/train_events_clean_new_no_timezone.csv\"\n",
    "    \n",
    "    # 读取文件\n",
    "    train_events = pl.read_csv(file_path)\n",
    "    \n",
    "    # 确保必要的列存在\n",
    "    required_cols = ['series_id', 'night', 'event', 'timestamp']\n",
    "    for col in required_cols:\n",
    "        if col not in train_events.columns:\n",
    "            print(f\"错误: 文件中不存在{col}列!\")\n",
    "            return\n",
    "    \n",
    "    # 转换timestamp为datetime类型\n",
    "    train_events = train_events.with_columns(\n",
    "        pl.col('timestamp').str.to_datetime()\n",
    "    )\n",
    "    \n",
    "    # 按series_id、night分组，并按timestamp排序\n",
    "    print(\"按series_id和night分组并排序...\")\n",
    "    grouped_events = train_events.group_by(['series_id', 'night']).agg([\n",
    "        pl.col('event').sort_by('timestamp').alias('sorted_events')\n",
    "    ])\n",
    "    \n",
    "    # 验证每个分组\n",
    "    print(\"验证每个分组的事件交替性...\")\n",
    "    issues = []\n",
    "    \n",
    "    for row in grouped_events.iter_rows(named=True):\n",
    "        series_id = row['series_id']\n",
    "        night = row['night']\n",
    "        events = row['sorted_events']\n",
    "        \n",
    "        # 检查1: onset和wakeup数量是否相等\n",
    "        onset_count = events.count('onset')\n",
    "        wakeup_count = events.count('wakeup')\n",
    "        \n",
    "        if onset_count != wakeup_count:\n",
    "            issues.append({\n",
    "                'series_id': series_id,\n",
    "                'night': night,\n",
    "                'issue': f'事件数量不匹配: onset={onset_count}, wakeup={wakeup_count}'\n",
    "            })\n",
    "            continue\n",
    "        \n",
    "        # 检查2: 事件是否交替出现\n",
    "        valid_sequence = True\n",
    "        for i, event in enumerate(events):\n",
    "            if i == 0:\n",
    "                # 第一个事件应该是onset\n",
    "                if event != 'onset':\n",
    "                    valid_sequence = False\n",
    "                    issues.append({\n",
    "                        'series_id': series_id,\n",
    "                        'night': night,\n",
    "                        'issue': f'第一个事件应该是onset，实际是{event}'\n",
    "                    })\n",
    "                    break\n",
    "            else:\n",
    "                # 检查事件交替\n",
    "                prev_event = events[i-1]\n",
    "                if (prev_event == 'onset' and event != 'wakeup') or \\\n",
    "                   (prev_event == 'wakeup' and event != 'onset'):\n",
    "                    valid_sequence = False\n",
    "                    issues.append({\n",
    "                        'series_id': series_id,\n",
    "                        'night': night,\n",
    "                        'issue': f'事件交替错误: {prev_event}后应该是{[\"wakeup\" if prev_event == \"onset\" else \"onset\"][0]}，实际是{event}'\n",
    "                    })\n",
    "                    break\n",
    "    \n",
    "    # 输出验证结果\n",
    "    print(f\"\\n验证完成! 总共检查了 {len(grouped_events)} 个夜晚的事件序列\")\n",
    "    \n",
    "    if len(issues) == 0:\n",
    "        print(\"✓ 所有事件序列都符合要求:\")\n",
    "        print(\"  - 每个夜晚的onset和wakeup数量相等\")\n",
    "        print(\"  - 事件交替出现（onset后是wakeup，wakeup后是onset）\")\n",
    "        print(\"  - 每个夜晚以onset开始，以wakeup结束\")\n",
    "    else:\n",
    "        print(f\"✗ 发现 {len(issues)} 个问题:\")\n",
    "        for issue in issues[:10]:  # 只显示前10个问题\n",
    "            print(f\"  series_id: {issue['series_id']}, night: {issue['night']}, 问题: {issue['issue']}\")\n",
    "        \n",
    "        if len(issues) > 10:\n",
    "            print(f\"  ... 还有 {len(issues) - 10} 个问题未显示\")\n",
    "    \n",
    "    return len(issues) == 0\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    validate_event_alternation()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
